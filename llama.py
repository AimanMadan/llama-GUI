import subprocess
import tkinter as tk
from tkinter import scrolledtext, messagebox
import re
import threading
import time

# Function to clean up ANSI escape sequences and control characters
def clean_output(output):
    # Regex to remove ANSI escape sequences and control characters
    ansi_escape = re.compile(r'\x1B[@-_][0-?]*[ -/]*[@-~]')
    return ansi_escape.sub('', output)

def ollama(model_name, prompt):
    """
    Run the 'ollama' command with the given model and prompt.

    Parameters:
    - model_name: Name of the model to use with ollama.
    - prompt: The input prompt string.

    Returns:
    - The cleaned output generated by ollama as a string.
    """
    try:
        # Build the command without the prompt argument
        command = ['ollama', 'run', model_name]
        # Execute the command, passing the prompt via stdin
        result = subprocess.run(
            command,
            input=prompt,
            capture_output=True,
            text=True,
            encoding='utf-8'  # Explicitly specify encoding
        )
        # Check for errors
        if result.returncode != 0:
            error_message = clean_output(result.stderr)
            messagebox.showerror("Error", f"Error running ollama:\n{error_message}")
            return None
        # Clean and return the standard output
        return clean_output(result.stdout).strip()
    except FileNotFoundError:
        messagebox.showerror("Error", "Error: 'ollama' command not found. Please ensure that ollama is installed and in your PATH.")
        return None
    except Exception as e:
        messagebox.showerror("Error", f"An unexpected error occurred:\n{str(e)}")
        return None

def send_prompt():
    prompt = prompt_entry.get()
    if not prompt:
        return
    model = model_entry.get()
    if not model:
        messagebox.showwarning("Warning", "Please enter a model name.")
        return
    chat_history.configure(state='normal')
    chat_history.insert(tk.END, f"You: {prompt}\n")
    chat_history.configure(state='disabled')
    prompt_entry.delete(0, tk.END)
    
    # Start a new thread to handle the Ollama response
    threading.Thread(target=handle_response, args=(model, prompt), daemon=True).start()

def handle_response(model, prompt):
    response = ollama(model, prompt)
    if response:
        # Display Ollama's response with typing effect
        type_text(f"Ollama: {response}\n")

def type_text(text, delay=0.02):
    """
    Display text in the chat history with a typing effect.

    Parameters:
    - text: The text to display.
    - delay: Delay between each character (in seconds).
    """
    chat_history.configure(state='normal')
    for char in text:
        chat_history.insert(tk.END, char)
        chat_history.see(tk.END)
        chat_history.update_idletasks()
        time.sleep(delay)
    chat_history.configure(state='disabled')

def on_enter(event):
    send_prompt()

# Create the main window
root = tk.Tk()
root.title("Ollama GUI Interface")

# Model frame
model_frame = tk.Frame(root)
model_frame.pack(pady=5)
model_label = tk.Label(model_frame, text="Model Name:")
model_label.pack(side=tk.LEFT)
model_entry = tk.Entry(model_frame)
model_entry.pack(side=tk.LEFT)

# Chat history
chat_history = scrolledtext.ScrolledText(root, wrap=tk.WORD, state='disabled', width=80, height=20)
chat_history.pack(padx=10, pady=10)

# Prompt frame
prompt_frame = tk.Frame(root)
prompt_frame.pack(pady=5)
prompt_label = tk.Label(prompt_frame, text="Prompt:")
prompt_label.pack(side=tk.LEFT)
prompt_entry = tk.Entry(prompt_frame, width=60)
prompt_entry.pack(side=tk.LEFT)
prompt_entry.bind('<Return>', on_enter)
send_button = tk.Button(prompt_frame, text="Send", command=send_prompt)
send_button.pack(side=tk.LEFT, padx=5)

# Start the GUI event loop
root.mainloop()
